# docker-compose.yml
version: '3.9'
volumes:
  models:
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    healthcheck:
      test: ["CMD-SHELL", "bash -lc 'echo > /dev/tcp/localhost/9092'"]
      interval: 5s
      timeout: 2s
      retries: 40
      start_period: 30s

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    depends_on:
      - kafka
    ports:
      - "8082:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181

  server:
    build: ./server
    ports:
      - "8085:8085"
    volumes:
      - ./common:/app/common
      - ./data:/data
      - ./models:/models
      - ./centralized_model:/app/centralized_model
    environment:
      - INIT_MODEL_DIR=/models/baseline
      - PYTHONPATH=/app
      - TZ=Asia/Kolkata
    command: ["python", "server.py"]

  client1:
    build: ./client1
    environment:
      - CLIENT_ID=1
      - BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TOPICS=amount_low
      - GROUP_ID=eda-client1
      - MAX_MESSAGES=200000        # adjust as you like
      - TIMEOUT_SEC=120            # stop waiting after 2 minutes
      - EDA_SAMPLE=200000          # optional downsample for plotting speed
      # - KEY_PATH=payload         # uncomment if your JSON nests the record
      # - STRICT_KEYS=true         # require all columns present
      - SCALER_PATH=/models/baseline/scaler.joblib
      - PYTHONPATH=/app
      - PREPROCESSOR_PATH=/models/baseline/preprocessor.joblib
      - META_PATH=/models/baseline/meta.json
      - TZ=Asia/Kolkata
      - MPLBACKEND=Agg
      - EDA_OUT_DIR=/data/eda/client1
    volumes:
      - ./common:/app/common
      - ./data:/data 
      - ./models:/models
    depends_on:
      kafka:
        condition: service_healthy
      server:
        condition: service_started
    working_dir: /app
    command: ["/bin/bash", "-c", "python /app/common/eda/eda_kafka_runner.py; python client.py"]


  client2:
    build: ./client1
    environment:
      - CLIENT_ID=2
      - BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TOPICS=amount_medium
      - GROUP_ID=eda-client2
      - MAX_MESSAGES=200000        # adjust as you like
      - TIMEOUT_SEC=120            # stop waiting after 2 minutes
      - EDA_SAMPLE=200000          # optional downsample for plotting speed
      # - KEY_PATH=payload         # uncomment if your JSON nests the record
      # - STRICT_KEYS=true         # require all columns present
      - SCALER_PATH=/models/baseline/scaler.joblib
      - PYTHONPATH=/app
      - PREPROCESSOR_PATH=/models/baseline/preprocessor.joblib
      - META_PATH=/models/baseline/meta.json
      - TZ=Asia/Kolkata
      - MPLBACKEND=Agg
      - EDA_OUT_DIR=/data/eda/client2
    volumes:
      - ./common:/app/common
      - ./data:/data 
      - ./models:/models
    depends_on:
      kafka:
        condition: service_healthy
      server:
        condition: service_started
    working_dir: /app
    command: ["/bin/bash", "-c", "python /app/common/eda/eda_kafka_runner.py; python client.py"]

  client3:
    build: ./client1
    environment:
      - CLIENT_ID=3
      - BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TOPICS=amount_high
      - GROUP_ID=eda-client3
      - MAX_MESSAGES=200000        # adjust as you like
      - TIMEOUT_SEC=120            # stop waiting after 2 minutes
      - EDA_SAMPLE=200000          # optional downsample for plotting speed
      # - KEY_PATH=payload         # uncomment if your JSON nests the record
      # - STRICT_KEYS=true         # require all columns present
      - SCALER_PATH=/models/baseline/scaler.joblib
      - PYTHONPATH=/app
      - PREPROCESSOR_PATH=/models/baseline/preprocessor.joblib
      - META_PATH=/models/baseline/meta.json
      - TZ=Asia/Kolkata
      - MPLBACKEND=Agg
      - EDA_OUT_DIR=/data/eda/client3
    volumes:
      - ./common:/app/common
      - ./data:/data 
      - ./models:/models
    depends_on:
      kafka:
        condition: service_healthy
      server:
        condition: service_started
    working_dir: /app
    command: ["/bin/bash", "-c", "python /app/common/eda/eda_kafka_runner.py; python client.py"]

  producer:
    build: ./producer
    environment:
      - PYTHONPATH=/app
      - META_PATH=/models/baseline/meta.json
      - TZ=Asia/Kolkata
    volumes:
      - ./producer:/app
      - ./common:/app/common
      - ./data:/data
      - ./models/baseline/meta.json:/models/baseline/meta.json:ro
    depends_on:
      - kafka
    command: ["python", "producer.py"]
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.13.0
    environment:
      - TZ=Asia/Kolkata
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlflow/mlruns
    command: > 
      mlflow server --backend-store-uri sqlite:///mlflow.db 
      --default-artifact-root /mlflow/mlruns 
      --host 0.0.0.0
